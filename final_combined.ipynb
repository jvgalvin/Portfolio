{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0c1d8b",
   "metadata": {},
   "source": [
    "# Adding Pickup Locations, Drones, and Using BART\n",
    "\n",
    "\n",
    "## Context\n",
    "\n",
    "Adding more pickup locations may help to grow the customer base and increase the frequency at which customers purchase meals. This would necessarily entail renting or purchasing property and/or renovating space to open these additional pickup locations.\n",
    "\n",
    "Since the business would be considering longer term leases or purchases with potential costly renovations, we need to choose locations which are future proof.\n",
    "\n",
    "Locations near BART stations would be good choices because riders could easily pick up meals at or near the stations they travel through on the way to or from work.\n",
    "\n",
    "[add stuff for drones]\n",
    "\n",
    "[add stuff for public transit]\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "We will cluster the BART stations to identify which stations naturally belong to certain groupings. For each cluster, we will examine each station's degree centrality, betweenness centrality, and PageRank. Degree centrality will indicate the number of stations connected to the station of interest. Betweenness centrality will indicate the number of routes which pass through that station. Finally, PageRank will indicate the overall influence of that station within the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e91e99",
   "metadata": {},
   "source": [
    "# Included Modules and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a61e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j\n",
    "\n",
    "import csv\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2\n",
    "from geographiclib.geodesic import Geodesic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d208d93",
   "metadata": {},
   "source": [
    "# Supporting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8317310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "\n",
    "driver = neo4j.GraphDatabase.driver(uri=\"neo4j://neo4j:7687\", auth=(\"neo4j\",\"w205\"))\n",
    "session = driver.session(database=\"neo4j\")\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    user = \"postgres\",\n",
    "    password = \"ucb\",\n",
    "    host = \"postgres\",\n",
    "    port = \"5432\",\n",
    "    database = \"postgres\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058e862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run a select query and return rows in a pandas dataframe\n",
    "# pandas puts all numeric values from postgres to float\n",
    "# if it will fit in an integer, change it to integer\n",
    "\n",
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    \"function to run a select query and return rows in a pandas dataframe\"\n",
    "    \n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    # fix the float columns that really should be integers\n",
    "    \n",
    "    for column in df:\n",
    "    \n",
    "        if df[column].dtype == \"float64\":\n",
    "\n",
    "            fraction_flag = False\n",
    "\n",
    "            for value in df[column].values:\n",
    "                \n",
    "                if not np.isnan(value):\n",
    "                    if value - math.floor(value) != 0:\n",
    "                        fraction_flag = True\n",
    "\n",
    "            if not fraction_flag:\n",
    "                df[column] = df[column].astype('Int64')\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff35f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_calculate_box(point, miles):\n",
    "    \"Given a point and miles, calculate the box in form left, right, top, bottom\"\n",
    "    \n",
    "    geod = Geodesic.WGS84\n",
    "\n",
    "    kilometers = miles * 1.60934\n",
    "    meters = kilometers * 1000\n",
    "\n",
    "    g = geod.Direct(point[0], point[1], 270, meters)\n",
    "    left = (g['lat2'], g['lon2'])\n",
    "\n",
    "    g = geod.Direct(point[0], point[1], 90, meters)\n",
    "    right = (g['lat2'], g['lon2'])\n",
    "\n",
    "    g = geod.Direct(point[0], point[1], 0, meters)\n",
    "    top = (g['lat2'], g['lon2'])\n",
    "\n",
    "    g = geod.Direct(point[0], point[1], 180, meters)\n",
    "    bottom = (g['lat2'], g['lon2'])\n",
    "    \n",
    "    return(left, right, top, bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236e450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_station_get_zips(station, miles):\n",
    "    \"given a station, pull all zip codes with miles distance, print them, sum the population\"\n",
    "    \n",
    "    connection.rollback()\n",
    "    \n",
    "    query = \"select latitude, longitude from stations \"\n",
    "    query += \"where station = '\" + station + \"'\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    \n",
    "    connection.rollback()\n",
    "    \n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        latitude = row[0]\n",
    "        longitude = row[1]\n",
    "        \n",
    "    point = (latitude, longitude)\n",
    "        \n",
    "    (left, right, top, bottom) = my_calculate_box(point, miles)\n",
    "    \n",
    "    query = \"select zip, population from zip_codes \"\n",
    "    query += \" where latitude >= \" + str(bottom[0])\n",
    "    query += \" and latitude <= \" + str(top [0])\n",
    "    query += \" and longitude >= \" + str(left[1])\n",
    "    query += \" and longitude <= \" + str(right[1])\n",
    "    query += \" order by 1 \"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    connection.rollback()\n",
    "    \n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    total_population = 0\n",
    "    \n",
    "    for row in rows:\n",
    "        zip, population = row[0], row[1]\n",
    "        total_population += population\n",
    "    return float(total_population)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f17d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_station_get_zip_list(station, miles):\n",
    "    \"given a station, pull all zip codes with miles distance, print them, sum the population\"\n",
    "    \n",
    "    connection.rollback()\n",
    "    \n",
    "    query = \"select latitude, longitude from stations \"\n",
    "    query += \"where station = '\" + station + \"'\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    \n",
    "    connection.rollback()\n",
    "    \n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        latitude = row[0]\n",
    "        longitude = row[1]\n",
    "        \n",
    "    point = (latitude, longitude)\n",
    "        \n",
    "    (left, right, top, bottom) = my_calculate_box(point, miles)\n",
    "    \n",
    "    query = \"select zip, population from zip_codes \"\n",
    "    query += \" where latitude >= \" + str(bottom[0])\n",
    "    query += \" and latitude <= \" + str(top [0])\n",
    "    query += \" and longitude >= \" + str(left[1])\n",
    "    query += \" and longitude <= \" + str(right[1])\n",
    "    query += \" order by 1 \"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    connection.rollback()\n",
    "    \n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    total_population = 0\n",
    "    \n",
    "    zip_list = []\n",
    "    \n",
    "    for row in rows:\n",
    "        zip = row[0]\n",
    "        population = row[1]\n",
    "        total_population += population\n",
    "        zip_list.append(row[0])\n",
    "    return zip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb9e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_stations(df):\n",
    "    \"\"\"Returns a data frame with unique station names cleansed of line(s) and depart, arrive\"\"\"\n",
    "    \n",
    "    words = [\"blue\", \"green\", \"orange\", \"red\", \"yellow\", \"orange\", \"gray\", \"depart\", \"arrive\"]\n",
    "    regex_pattern = r'\\b(?:{})\\b'.format('|'.join(words))\n",
    "    df[\"name\"] = df[\"name\"].str.replace(regex_pattern, '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694ac07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_neo4j_run_query_pandas(query, **kwargs):\n",
    "    \"run a query and return the results in a pandas dataframe\"\n",
    "    \n",
    "    result = session.run(query, **kwargs)\n",
    "    \n",
    "    df = pd.DataFrame([r.values() for r in result], columns=result.keys())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649e5ca",
   "metadata": {},
   "source": [
    "# Generate Data Frame for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d428a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollback_before_flag = True\n",
    "rollback_after_flag = True\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "select station,\n",
    "        latitude,\n",
    "        longitude\n",
    "from stations\n",
    "order by station\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = my_select_query_pandas(query, rollback_before_flag, rollback_after_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f819a2d",
   "metadata": {},
   "source": [
    "##### Add population within 1.5 miles of each station, which is the delivery range for a drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e279b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pop_1_5\"] = [my_station_get_zips(station, 1.5) for station in df[\"station\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa46a0c",
   "metadata": {},
   "source": [
    "##### Add degree centrality, which measures the number of incoming and outgoing connections. High degree centrality indicates that the station connects with many others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23c00dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree centrality for the connected graph\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "CALL gds.degree.stream('ds_graph')\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).name AS name, score as degree\n",
    "ORDER BY degree DESC, name\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "deg_df = my_neo4j_run_query_pandas(query)\n",
    "\n",
    "# Remove the line and depart / arrive designations\n",
    "\n",
    "deg_df = cleanse_stations(deg_df)\n",
    "\n",
    "# Keep the entry for each station with the maximum degree centrality\n",
    "\n",
    "deg_df = deg_df.groupby([\"name\"])[\"degree\"].max()\n",
    "deg_df = deg_df.to_frame()\n",
    "\n",
    "# Add degree centrality to df\n",
    "\n",
    "df.set_index(\"station\", inplace=True)\n",
    "df[\"degree_centrality\"] = deg_df[\"degree\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00075923",
   "metadata": {},
   "source": [
    "##### Add betweenness centrality, which measures the number of paths which pass through a node (station). High betweenness centrality for a station indicates a high number of paths which pass through that station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71230c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betweenness centrality\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "CALL gds.betweenness.stream('ds_graph')\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).name AS name, score as betweenness\n",
    "ORDER BY betweenness DESC\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "bet_df = my_neo4j_run_query_pandas(query)\n",
    "\n",
    "# Remove the line and depart / arrive designations\n",
    "\n",
    "bet_df = cleanse_stations(bet_df)\n",
    "\n",
    "# Keep the entry for each station with the maximum betweenness centrality\n",
    "\n",
    "bet_df = bet_df.groupby([\"name\"])[\"betweenness\"].max()\n",
    "bet_df = bet_df.to_frame()\n",
    "\n",
    "# Add degree centrality to df\n",
    "\n",
    "df[\"bet_centrality\"] = bet_df[\"betweenness\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ddc5b",
   "metadata": {},
   "source": [
    "##### Add PageRank for each station, which measures the influence of that station in the graph. High PageRank indicates an influential station in the BART map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0a3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PageRank for each station\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "CALL gds.pageRank.stream('ds_graph',\n",
    "                         { maxIterations: $max_iterations,\n",
    "                           dampingFactor: $damping_factor}\n",
    "                         )\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).name AS name, score as page_rank\n",
    "ORDER BY page_rank DESC, name ASC\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "max_iterations = 20\n",
    "damping_factor = 0.05\n",
    "\n",
    "pr_df = my_neo4j_run_query_pandas(query, max_iterations=max_iterations, damping_factor=damping_factor)\n",
    "\n",
    "# Remove the line and depart / arrive designations\n",
    "\n",
    "pr_df = cleanse_stations(pr_df)\n",
    "\n",
    "# Keep the entry for each station with the maximum page rank\n",
    "\n",
    "pr_df = pr_df.groupby([\"name\"])[\"page_rank\"].max()\n",
    "pr_df = pr_df.to_frame()\n",
    "\n",
    "# Add degree centrality to df\n",
    "\n",
    "df[\"page_rank\"] = pr_df[\"page_rank\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c4a43",
   "metadata": {},
   "source": [
    "##### Impute population values for Antioch, Milpitas, OAK, and Pittsburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a861cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollback_before_flag = True\n",
    "rollback_after_flag = True\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "select *\n",
    "from zip_codes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "temp = my_select_query_pandas(query, rollback_before_flag, rollback_after_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "599f844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the zip_codes table, find the population for each of the four corresponding zip codes\n",
    "\n",
    "antioch_station_zip = \"94509\"\n",
    "milpitas_station_zip = \"95035\"\n",
    "OAK_station_zip = \"94621\"\n",
    "pittsburg_station_zip = \"94565\"\n",
    "\n",
    "antioch_pop = int(temp.loc[temp[\"zip\"] == antioch_station_zip, \"population\"])\n",
    "milpitas_pop = int(temp.loc[temp[\"zip\"] == milpitas_station_zip, \"population\"])\n",
    "OAK_pop = int(temp.loc[temp[\"zip\"] == OAK_station_zip, \"population\"])\n",
    "pittsburg_pop = int(temp.loc[temp[\"zip\"] == pittsburg_station_zip, \"population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9445fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the population values back to the data frame\n",
    "\n",
    "df.loc[df.index==\"Antioch\", \"pop_1_5\"] = antioch_pop\n",
    "df.loc[df.index==\"Milpitas\", \"pop_1_5\"] = milpitas_pop\n",
    "df.loc[df.index==\"OAK\", \"pop_1_5\"] = OAK_pop\n",
    "df.loc[df.index==\"Pittsburg\", \"pop_1_5\"] = pittsburg_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932835fd",
   "metadata": {},
   "source": [
    "##### Cluster the stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c81a1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "CALL gds.louvain.stream('ds_graph')\n",
    "YIELD nodeId, communityId, intermediateCommunityIds\n",
    "RETURN gds.util.asNode(nodeId).name AS name, communityId as community, intermediateCommunityIds as intermediate_community\n",
    "ORDER BY community, name ASC\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Clean the results\n",
    "\n",
    "temp = my_neo4j_run_query_pandas(query)\n",
    "temp = cleanse_stations(temp)\n",
    "temp[\"name\"] = temp[\"name\"].str.lstrip()\n",
    "temp = temp.groupby(\"name\")[\"community\"].max().to_frame()\n",
    "temp[\"cluster\"] = [0 for i in range(0,50)]\n",
    "\n",
    "# Refine the cluster - Louvain returns too many clusters\n",
    "\n",
    "temp.loc[temp[\"community\"] < temp[\"community\"].quantile(0.25), \"cluster\"] = 1\n",
    "temp.loc[(temp[\"community\"] >= temp[\"community\"].quantile(0.25)) & \n",
    "         (temp[\"community\"] < temp[\"community\"].quantile(0.5)), \"cluster\"] = 2\n",
    "temp.loc[(temp[\"community\"] >= temp[\"community\"].quantile(0.5)) & \n",
    "     (temp[\"community\"] < temp[\"community\"].quantile(0.75)), \"cluster\"] = 3\n",
    "temp.loc[temp[\"community\"] >= temp[\"community\"].quantile(0.75), \"cluster\"] = 4\n",
    "\n",
    "# Drop community\n",
    "\n",
    "temp.drop(\"community\", axis=1, inplace=True)\n",
    "\n",
    "# Append to df\n",
    "\n",
    "df[\"cluster\"] = temp[\"cluster\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e0390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
