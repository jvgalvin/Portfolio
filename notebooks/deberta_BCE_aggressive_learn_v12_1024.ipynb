{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!mkdir -p ./data/raw\n",
        "!mkdir -p ./data/processed\n",
        "!gdown 1pv7dFLniLEMJXXk5-YL3_kWxpOs7ueJt -O ./data.zip\n",
        "!unzip ./data.zip -d ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTcW735Fh46U",
        "outputId": "b0b81ad5-e509-49bf-c9dc-76cf019a88f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pv7dFLniLEMJXXk5-YL3_kWxpOs7ueJt\n",
            "To: /content/data.zip\n",
            "100% 9.35M/9.35M [00:00<00:00, 101MB/s]\n",
            "Archive:  ./data.zip\n",
            "replace ./data/processed/wiki_masks.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cboHJMR6imu5",
        "outputId": "e9053873-3243-4c17-94dc-c5e2f1b72b66"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  2 05:20:51 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    55W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "!pip install transformers[sentencepiece]\n",
        "!pip install torch\n",
        "!pip install json\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpfh4gxGi4J3",
        "outputId": "b4d9d74c-19c5-4557-978c-7a43013faf82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.8/dist-packages (0.13.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.1.97)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers[sentencepiece]) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for json\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8TV2efoQf_11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4e53e1-3fbc-4cf3-ed7e-9f8d13399a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 304/304 [04:11<00:00,  1.21it/s]\n",
            "100%|██████████| 64/64 [00:12<00:00,  5.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.39300183961658103 Valid Loss = 0.3794362966436893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 304/304 [04:09<00:00,  1.22it/s]\n",
            "100%|██████████| 64/64 [00:12<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.3773673694874895 Valid Loss = 0.37820300459861755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 304/304 [04:09<00:00,  1.22it/s]\n",
            "100%|██████████| 64/64 [00:12<00:00,  5.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.3761805986103259 Valid Loss = 0.37758310744538903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 304/304 [04:10<00:00,  1.21it/s]\n",
            "100%|██████████| 64/64 [00:12<00:00,  5.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.37531874573936586 Valid Loss = 0.3770640129223466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 304/304 [04:10<00:00,  1.21it/s]\n",
            "100%|██████████| 64/64 [00:12<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.37453652785992936 Valid Loss = 0.3766436195001006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 304/304 [04:09<00:00,  1.22it/s]\n",
            "100%|██████████| 64/64 [00:12<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.37367478164991264 Valid Loss = 0.37627602368593216\n"
          ]
        }
      ],
      "source": [
        "import tokenizers\n",
        "import transformers\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import DebertaV2TokenizerFast\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import sentencepiece\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "VERSION = 'v12.BCE.1024'\n",
        "#max token input length\n",
        "MAX_LEN = 1024  #768 for small\n",
        "TRAIN_BATCH_SIZE = 3#32\n",
        "VALID_BATCH_SIZE = 2#8\n",
        "EPOCHS =6 #10\n",
        "BASE_MODEL = 'microsoft/deberta-v3-large'\n",
        "#BASE_MODEL = 'microsoft/deberta-v3-small'\n",
        "\n",
        "MODEL_PATH = \"model_\" + BASE_MODEL.replace('/','_') + \"_\" + VERSION + \".bin\"\n",
        "TOKENIZER = DebertaV2TokenizerFast.from_pretrained(BASE_MODEL)\n",
        "\n",
        "DEV_FILE = \"./data/raw/text-anonymization-benchmark/echr_dev.json\"\n",
        "TRAINING_FILE = \"./data/raw/text-anonymization-benchmark/echr_train.json\"\n",
        "TEST_FILE = \"./data/raw/text-anonymization-benchmark/echr_test.json\"\n",
        "\n",
        "DEV_MASKS_FILE =    \"./data/processed/jg_dev_masks.json\"\n",
        "TRAIN_MASKS_FILE =  \"./data/processed/jg_train_masks.json\"\n",
        "TEST_MASKS_FILE =   \"./data/processed/jg_test_masks.json\"\n",
        "\n",
        "class EntityDataset:\n",
        "    def __init__(self, texts, ids, labels, offsets, masks):\n",
        "        # ids: [[    0,  4454,  4571,  1691, 12435, 50118, ..., 4, 2], [0, 50118,   133,   403, 19575,    11,    41, ..., 2]]\n",
        "        # texts - original texts\n",
        "        # offsets - mapping of tokens to text \n",
        "        # labels: is token an identifier: [[0,0,0,0,1,1,0,0, ...,], [0,0,1,0,0,...]]\n",
        "        self.texts = texts\n",
        "        self.ids = ids\n",
        "        self.offsets = offsets\n",
        "        self.labels = labels\n",
        "        self.masks = masks\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        ids = self.ids[item]\n",
        "        masks = self.masks[item]\n",
        "        \n",
        "        target_labels =self.labels[item]\n",
        "        #pad if we need to\n",
        "        if len(target_labels) < MAX_LEN:\n",
        "            target_labels = np.pad(target_labels, (0,MAX_LEN-target_labels.size),'constant', constant_values=(0))\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"masks\": torch.tensor(masks, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(target_labels, dtype=torch.float32),\n",
        "        }\n",
        "    #for debugging\n",
        "    def printItem(i):\n",
        "        masked_doc_text=''\n",
        "        for token, offset, label in zip(tokens, offsets, labels):\n",
        "            if label == 1:\n",
        "                #masked_doc_text.append(\"[MASK]\")\n",
        "                str=\"*\" + texts[offset[0]:offset[1]] +\"*\"        \n",
        "                masked_doc_text.append(str)\n",
        "            else:\n",
        "                masked_doc_text.append(texts[offset[0]:offset[1]])\n",
        "        print(masked_doc_text)\n",
        "\n",
        "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    final_loss = 0\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        _, loss = model(**data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        final_loss += loss.item()\n",
        "    return final_loss / len(data_loader)\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    final_loss = 0\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        _, loss = model(**data)\n",
        "        final_loss += loss.item()\n",
        "    return final_loss / len(data_loader)\n",
        "\n",
        "def loss_fn(out_logits, target, mask):\n",
        "    lfn = nn.BCELoss()\n",
        "    m = nn.Sigmoid()    \n",
        "    loss = lfn(m(out_logits[:,0:target.shape[1]]), target)\n",
        "    return loss\n",
        "\n",
        "class MeanPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MeanPooling, self).__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, labels, attention_mask):\n",
        "        #last_hidden_state.shape = [|b|,768,1024].  For deberta-small: [|b|,768,768]\n",
        "        #attention_mask = [[1,1,1,1... 1,0,0,0]].  attention_mask.shape = [1,768].  For deberta-small = [768, 32]\n",
        "        #desired output shape: [|b|, 768]\n",
        "        #unsqueeze to add 1 dim, then duplicate in dimension to match the second hidden state dim (768)\n",
        "        #tt_mask = attention_mask\n",
        "        #input_mask_expanded = tt_mask.expand(last_hidden_state.shape[1]).float()  \n",
        "        #sum the hidden state tensor along the 2 dimension (1024)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()  \n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)   \n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        mean_embeddings = sum_embeddings / sum_mask\n",
        "        return mean_embeddings\n",
        "\n",
        "class EntityModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EntityModel, self).__init__()\n",
        "        #full config\n",
        "        #https://huggingface.co/docs/transformers/model_doc/deberta-v2\n",
        "        self.config = AutoConfig.from_pretrained(BASE_MODEL, return_dict=True)\n",
        "        self.m = AutoModel.from_pretrained(BASE_MODEL, config=self.config) \n",
        "        self.mpool = MeanPooling()\n",
        "    \n",
        "    def forward(self, ids, masks, labels):\n",
        "        output = self.m(ids, attention_mask=masks)\n",
        "        mpool = self.mpool(output.last_hidden_state, labels, masks)\n",
        "        loss_labels = loss_fn(mpool, labels, masks)        \n",
        "        return labels, loss_labels\n",
        "\n",
        "# Function used to label data\n",
        "def label_tokens(toks, offs, spans_to_mask):\n",
        "    \"\"\"Args: \n",
        "            toks - list of token id's\n",
        "            offs - list of char offsets for each token\n",
        "       Returns:\n",
        "            label_list - 0 for non_mask, 1 for mask\"\"\"\n",
        "    \n",
        "    label_list = []\n",
        "    mapping_list = []    \n",
        "    # Map token_ids back to string    \n",
        "    for token, pos in zip(toks, offs):\n",
        "        mapping_list.append([token, pos[0], pos[1]])\n",
        "    \n",
        "    # Determine if each token should be masked\n",
        "    spans_to_mask.sort(key=lambda tup: tup[0]) #order spans, ascending\n",
        "    \n",
        "    j=0\n",
        "    for i in range(len(mapping_list)):\n",
        "        temp_list = []\n",
        "        stop=False        \n",
        "        while not stop and j < len(spans_to_mask):            \n",
        "            if ((mapping_list[i][1] >= spans_to_mask[j][0]) and (mapping_list[i][1] < spans_to_mask[j][1])) or ((mapping_list[i][2] >= spans_to_mask[j][0]) and (mapping_list[i][2] < spans_to_mask[j][1])):\n",
        "                temp_list.append(1)\n",
        "            else:\n",
        "                temp_list.append(0)           \n",
        "\n",
        "            # Since spans and mapping_list are ordered, break to allow it to catch up\n",
        "            if(spans_to_mask[j][1] > mapping_list[i][2]):\n",
        "                stop=True\n",
        "            else:\n",
        "                j = j+1\n",
        "            \n",
        "        if sum(temp_list) >= 1:\n",
        "            label_list.append(1)\n",
        "        else:\n",
        "            label_list.append(0)\n",
        "    return label_list  \n",
        "\n",
        "def process_data(data_path, masks_path):\n",
        "    with open(data_path) as file:\n",
        "        file = json.load(file)\n",
        "\n",
        "    with open(masks_path) as masks_file:\n",
        "        train_masks = json.load(masks_file)\n",
        "\n",
        "    text = []\n",
        "    tokens = []\n",
        "    offsets = []\n",
        "    labels = []\n",
        "    masks = []\n",
        "\n",
        "    for i in range(len(file)):\n",
        "        doc_id = file[i][\"doc_id\"]\n",
        "        spans_to_mask = train_masks[doc_id]\n",
        "        spans_to_mask = list({tuple(x) for x in spans_to_mask}) # Make spans unique\n",
        "        doc_text = file[i][\"text\"]\n",
        "        tok_tensor = TOKENIZER(\n",
        "            doc_text,\n",
        "            add_special_tokens=True,            \n",
        "            max_length=MAX_LEN,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',            #pytorch tensors\n",
        "            return_offsets_mapping = True\n",
        "        )\n",
        "        \n",
        "        doc_tokens = tok_tensor[\"input_ids\"].numpy()[0]\n",
        "        doc_offsets = tok_tensor[\"offset_mapping\"].numpy()[0]\n",
        "        masks_ = tok_tensor[\"attention_mask\"].numpy()[0]\n",
        "       \n",
        "        labels.append(label_tokens(doc_tokens, doc_offsets, spans_to_mask))\n",
        "        masks.append(masks_)\n",
        "        tokens.append(doc_tokens)\n",
        "        offsets.append(doc_offsets)\n",
        "        text.append(doc_text)\n",
        "  \n",
        "    return text, tokens, labels, offsets, masks\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":    \n",
        "    texts, tokens, labels, offsets, masks = process_data(TRAINING_FILE, TRAIN_MASKS_FILE)\n",
        "\n",
        "    #Split train into train and test.  0.9/0.1 split\n",
        "    (\n",
        "        train_texts,\n",
        "        test_texts,\n",
        "        train_tokens,\n",
        "        test_tokens,\n",
        "        train_labels,\n",
        "        test_labels,\n",
        "        train_offsets,\n",
        "        test_offsets,\n",
        "        train_masks,\n",
        "        test_masks\n",
        "    ) = model_selection.train_test_split(texts, tokens, labels, offsets, masks, random_state=42, test_size=0.1)\n",
        "\n",
        "    train_dataset = EntityDataset(\n",
        "        texts=train_texts, ids=train_tokens, labels=train_labels, offsets=train_offsets, masks=train_masks\n",
        "    )\n",
        "    test_dataset = EntityDataset(\n",
        "        texts=test_texts, ids=test_tokens, labels=test_labels, offsets=test_offsets, masks=test_masks\n",
        "    )\n",
        "\n",
        "    texts, tokens, labels, offsets, masks = process_data(DEV_FILE, DEV_MASKS_FILE)\n",
        "    dev_dataset = EntityDataset(\n",
        "        texts=texts, ids=tokens, labels=labels, offsets=offsets, masks=masks\n",
        "    )\n",
        "    dev_data_loader = torch.utils.data.DataLoader(\n",
        "        dev_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=4\n",
        "    )\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=4\n",
        "    )\n",
        "\n",
        "    texts, tokens, labels, offsets, masks = process_data(TEST_FILE, TEST_MASKS_FILE)\n",
        "    valid_dataset = EntityDataset(\n",
        "        texts=texts, ids=tokens, labels=labels, offsets=offsets, masks=masks\n",
        "    )\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=VALID_BATCH_SIZE, num_workers=1\n",
        "    )\n",
        "\n",
        "    device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = EntityModel()\n",
        "    model.to(device)\n",
        "\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_parameters = [\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "            ],\n",
        "            \"weight_decay\": 0.001,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "            ],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    num_train_steps = int(len(train_texts) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=6e-2)\n",
        "    \n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_loss = np.inf\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
        "        test_loss = eval_fn(valid_data_loader, model, device)\n",
        "        print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\n",
        "        if test_loss < best_loss:\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            best_loss = test_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "id": "8BwWrNzjRuYQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "0106acb4-d985-4b60-af4c-4f8066796a3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    6626 MB |   27561 MB |  268062 GB |  268056 GB |\\n|       from large pool |    6621 MB |   27543 MB |  268024 GB |  268018 GB |\\n|       from small pool |       4 MB |      18 MB |      38 GB |      38 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    6626 MB |   27561 MB |  268062 GB |  268056 GB |\\n|       from large pool |    6621 MB |   27543 MB |  268024 GB |  268018 GB |\\n|       from small pool |       4 MB |      18 MB |      38 GB |      38 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    9200 MB |   27774 MB |   27774 MB |   18574 MB |\\n|       from large pool |    9192 MB |   27754 MB |   27754 MB |   18562 MB |\\n|       from small pool |       8 MB |      20 MB |      20 MB |      12 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    2573 MB |   11364 MB |  103211 GB |  103209 GB |\\n|       from large pool |    2570 MB |   11361 MB |  103162 GB |  103160 GB |\\n|       from small pool |       3 MB |       6 MB |      48 GB |      48 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1561    |    2599    |    7928 K  |    7926 K  |\\n|       from large pool |     584    |    1409    |    6279 K  |    6278 K  |\\n|       from small pool |     977    |    1192    |    1648 K  |    1647 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1561    |    2599    |    7928 K  |    7926 K  |\\n|       from large pool |     584    |    1409    |    6279 K  |    6278 K  |\\n|       from small pool |     977    |    1192    |    1648 K  |    1647 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     110    |     212    |     212    |     102    |\\n|       from large pool |     106    |     202    |     202    |      96    |\\n|       from small pool |       4    |      10    |      10    |       6    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      52    |     264    |    3910 K  |    3909 K  |\\n|       from large pool |      45    |     192    |    3296 K  |    3296 K  |\\n|       from small pool |       7    |      72    |     613 K  |     613 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN_W = 1024 # 730 is Longest sequence in wiki dataset\n",
        "# Load wiki data\n",
        "\n",
        "with open(\"./data/raw/wiki-summaries/annotated_wikipedia.json\") as file:\n",
        "    wiki_file = json.load(file)\n",
        "\n",
        "with open(\"./data/processed/wiki_masks.json\") as file:\n",
        "    wiki_masks = json.load(file)"
      ],
      "metadata": {
        "id": "9kJ6zPwH9pJW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels\n",
        "wiki_text = []\n",
        "wiki_labels = []\n",
        "wiki_offsets = []\n",
        "wiki_tokens = []\n",
        "\n",
        "for i in range(len(wiki_file)):\n",
        "    doc_id = wiki_file[i][\"doc_id\"]\n",
        "    spans_to_mask = wiki_masks[doc_id]\n",
        "    spans_to_mask = list({tuple(x) for x in spans_to_mask}) # Make spans unique\n",
        "    doc_text = wiki_file[i][\"text\"]\n",
        "    #tok_tensor = tokenizer(doc_text, return_tensors=\"tf\", truncation=True, padding=True, return_offsets_mapping=True)\n",
        "    tok_tensor = TOKENIZER(\n",
        "            doc_text,\n",
        "            add_special_tokens=True,            \n",
        "            max_length=MAX_LEN_W,\n",
        "            truncation=True,                #Truncate at MAX_LEN for now.  Can try setting MAX_LEN to the longest text.\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping = True\n",
        "        )\n",
        "    tokens = tok_tensor[\"input_ids\"].numpy()[0]\n",
        "    #tokens = tok_tensor[\"input_ids\"].numpy()[0]\n",
        "    offsets = tok_tensor[\"offset_mapping\"].numpy()[0]\n",
        "    wiki_text.append(doc_text)\n",
        "    wiki_labels.append(label_tokens(tokens, offsets, spans_to_mask))\n",
        "    wiki_offsets.append(offsets)\n",
        "    wiki_tokens.append(tokens)"
      ],
      "metadata": {
        "id": "sjc-YMOI-Vqz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad labels to max length\n",
        "def pad(arr):\n",
        "  for i in range(len(arr)):\n",
        "      curr_len = len(arr[i])\n",
        "      \n",
        "      if curr_len < MAX_LEN_W:\n",
        "          to_add = [0] * (MAX_LEN_W - curr_len)\n",
        "          arr[i].extend(to_add)\n",
        "          \n",
        "  arr = np.asarray(arr)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "iG4BHHa9_IPA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input\n",
        "#wiki_text_tokenized = TOKENIZER(wiki_text, truncation=True, max_length=768, padding=True, return_tensors=\"pt\")\n",
        "wiki_text_tokenized = TOKENIZER(\n",
        "            wiki_text,\n",
        "            add_special_tokens=True,            \n",
        "            max_length=MAX_LEN_W,\n",
        "            truncation=True,                #Truncate at MAX_LEN for now.  Can try setting MAX_LEN to the longest text.\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping = False\n",
        "        )"
      ],
      "metadata": {
        "id": "uRGEeIoq_QEf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = EntityModel()\n",
        "loaded_model = loaded_model.to(device)\n",
        "loaded_model.load_state_dict(torch.load(MODEL_PATH))\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "id": "PNMtP5y3OC-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f5c48c0-6d65-44a9-ff87-c27d0227c487"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EntityModel(\n",
              "  (m): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (12): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (13): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (14): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (15): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (16): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (17): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (18): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (19): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (20): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (21): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (22): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (23): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (mpool): MeanPooling()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_labels_pad = pad(wiki_labels)\n",
        "ids_wiki= wiki_text_tokenized[\"input_ids\"]\n",
        "ids_wiki = F.pad(ids_wiki, (0,MAX_LEN - ids_wiki.shape[-1]))\n",
        "labels_wiki = torch.tensor(wiki_labels_pad, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "31dJumqsIgXo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_test = torch.tensor(test_dataset.ids, dtype=torch.int64)\n",
        "labels_test = torch.tensor(test_dataset.labels, dtype=torch.float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7hBhqpnuGCZ",
        "outputId": "05ebc4f1-c9f0-44fe-f627-b1f017df80ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e5c38785abf1>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  ids_test = torch.tensor(test_dataset.ids, dtype=torch.int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getPredictionsAndTokenCounts(ids_a, labels_a):\n",
        "  ids_a = ids_a.to(device)\n",
        "  labels_a = labels_a.to(device)\n",
        "  zero_masks = torch.zeros_like(ids_a)\n",
        "  zero_masks = zero_masks.to(device)\n",
        "\n",
        "  predictions=[] \n",
        "\n",
        "  with torch.no_grad():\n",
        "    batch_size=20\n",
        "    for i in range(0, ids_a.shape[0], batch_size):\n",
        "        num_in_batch = min(i+batch_size, ids_a.shape[0])\n",
        "        indices = range(i, num_in_batch)\n",
        "        ids_batch = ids_a[indices]\n",
        "        pred_logits, _ = loaded_model(ids= ids_batch, labels=labels_a[indices], masks=zero_masks[indices])\n",
        "        pred_logits = pred_logits.to(\"cpu\", dtype=torch.float)\n",
        "        predictions.append(pred_logits.tolist()[0])\n",
        "\n",
        "  token_len = []\n",
        "  ids_a = ids_a.to(\"cpu\", dtype=torch.int)\n",
        "  for idx in range(0, len(ids_a)):\n",
        "    nonTokens = np.where(ids_a[idx] ==0)[0]\n",
        "    if(len(nonTokens)==0):\n",
        "      token_len.append(MAX_LEN_W)\n",
        "    else:\n",
        "      token_len.append(nonTokens[0])\n",
        "\n",
        "  return [predictions, token_len]"
      ],
      "metadata": {
        "id": "3ZqkEhJJFcaw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions_wiki, token_counts_wiki = getPredictionsAndTokenCounts(ids_wiki, labels_wiki)\n",
        "data_name=\"wiki\"\n",
        "np.savetxt(\"./\" + MODEL_PATH + \"_\" + data_name + \"_preds.txt\", predictions_wiki)\n",
        "\n",
        "predictions_test, token_counts_test = getPredictionsAndTokenCounts(ids_test, labels_test)\n",
        "data_name=\"test\"\n",
        "np.savetxt(\"./\" + MODEL_PATH + \"_\" + data_name + \"_preds.txt\", predictions_test)"
      ],
      "metadata": {
        "id": "AhFa2EPXme0y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for debugging\n",
        "def printExample(doc_text, tokens, offsets, labels):\n",
        "    masked_doc_text=['']\n",
        "    for idx, offset in enumerate(offsets):\n",
        "        \n",
        "        #zip(self.ids[i], , self.labels[i])\n",
        "        if labels[idx] == 1:\n",
        "            #masked_doc_text.append(\"[MASK]\")\n",
        "            run=\"*\" + doc_text[offset[0]:offset[1]] +\"[start:\" + str(offset[0]) + \",end:\" + str(offset[1]) + \". \" + str(tokens[idx]) + \"]*\"        \n",
        "            masked_doc_text.append(run)\n",
        "        else:\n",
        "            masked_doc_text.append(doc_text[offset[0]:offset[1]])\n",
        "    print(''.join(masked_doc_text))\n",
        "    print(masked_doc_text)\n",
        "\n",
        "def printWikiExample(i, labels=wiki_labels):\n",
        "    printExample(wiki_text[i], wiki_tokens[i], wiki_offsets[i], labels[i])"
      ],
      "metadata": {
        "id": "YAgnE_LdUq0F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printWikiExample(2, labels = predictions)"
      ],
      "metadata": {
        "id": "Wwn7pYECUssV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions[0]\n",
        "#wiki_labels[0]\n",
        "#item_i = 5\n",
        "#for idx in range(0, token_len[item_i]+5):\n",
        "#  print(str(idx) + \":\" + str(predictions[item_i][idx]) + \" \" + str(wiki_labels[item_i][idx]) + \" token: \" + str(wiki_tokens[item_i][idx]))"
      ],
      "metadata": {
        "id": "ziNaeEF0ygk3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_precision(pred_list, label_list, token_len):\n",
        "    \"\"\"Calculates precision of batch of predictions\"\"\"\n",
        "    \n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    \n",
        "    for i in range(len(pred_list)):\n",
        "        for j in range(token_len[i]):\n",
        "          \n",
        "            if pred_list[i][j] == 1:\n",
        "                if label_list[i][j] == 1:\n",
        "                    tp += 1\n",
        "                else:\n",
        "                    fp += 1\n",
        "            else:\n",
        "                continue\n",
        "                \n",
        "    return tp / (tp + fp)"
      ],
      "metadata": {
        "id": "Xkh0mzBOlzOl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_recall(pred_list, label_list, token_len):\n",
        "    \"\"\"Calculates recall of batch of predictions\"\"\"\n",
        "    \n",
        "    tp = 0 \n",
        "    fn = 0\n",
        "    \n",
        "    for i in range(len(pred_list)):\n",
        "        for j in range(token_len[i]):\n",
        "            \n",
        "            if pred_list[i][j] == 1:\n",
        "                if label_list[i][j] == 1:\n",
        "                    tp += 1\n",
        "                else:\n",
        "                    tp += 0\n",
        "                \n",
        "            else:\n",
        "                if label_list[i][j] == 1:\n",
        "                    fn += 1\n",
        "                else:\n",
        "                    fn += 0\n",
        "    \n",
        "    return tp / (tp + fn)"
      ],
      "metadata": {
        "id": "UFaKfaJQl0Pc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions_wiki, token_counts_wiki, ids_wiki, labels_wiki\n",
        "def calc_stats(ids, predictions, labels, token_counts):\n",
        "  precision = calc_precision(predictions, labels, token_counts)\n",
        "  print (f' Token level precision: {precision}')\n",
        "  recall = calc_recall(predictions, labels, token_counts)\n",
        "  print (f' Token level recall: {recall}')\n",
        "\n",
        "  auc = []\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "      fpr, tpr, thresholds = metrics.roc_curve(wiki_labels[i][0:token_counts[i]], predictions[i][0:token_counts[i]], pos_label=1)\n",
        "      auc.append(metrics.auc(fpr, tpr))\n",
        "\n",
        "  auc = sum(auc)/len(auc)\n",
        "  print (f' Average AUC: {auc}')\n",
        "\n",
        "  f1 = (2*precision*recall)/(precision+recall)\n",
        "  print (f' F1 Score: {f1}')"
      ],
      "metadata": {
        "id": "jAy8K7BdZGBu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#precision = calc_precision(predictions, test_labels, token_len)\n",
        "#print (f' Token level precision: {precision}')\n",
        "#recall = calc_recall(predictions, test_labels, token_len)\n",
        "#print (f' Token level recall: {recall}')"
      ],
      "metadata": {
        "id": "Lolu8cAHFJRq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Stats for Wiki Set\")\n",
        "calc_stats(ids_wiki, predictions_wiki, labels_wiki, token_counts_wiki)\n",
        "\n",
        "print(\"Stats for Test Set\")\n",
        "calc_stats(ids_test, predictions_test, labels_test, token_counts_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcDGdWZWMo-7",
        "outputId": "573fb2e8-6cdb-420a-e12e-558e9c4029c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stats for Wiki Set\n",
            " Token level precision: 0.5182724252491694\n",
            " Token level recall: 0.2608695652173913\n",
            " Average AUC: 0.5696334209415517\n",
            " F1 Score: 0.3470522803114572\n",
            "Stats for Test Set\n",
            " Token level precision: 0.3483443708609272\n",
            " Token level recall: 0.31235154394299286\n",
            " Average AUC: 0.4793989889278088\n",
            " F1 Score: 0.32936756418284285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "F1YTGAq_l2p8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}