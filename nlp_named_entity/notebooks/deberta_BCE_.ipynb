{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aed0441557fa4ad683ecfdf43c0c9ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_791a96d746bf494aa70bef1c823004bf",
              "IPY_MODEL_40b2539e54d945929de4cd10acfd7b7d",
              "IPY_MODEL_e55de2a6365e462bbeb3636fd008ac08"
            ],
            "layout": "IPY_MODEL_ac4544ac21e54e15ad79abad453c5591"
          }
        },
        "791a96d746bf494aa70bef1c823004bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffbba42282654e94a9993d4e820c1d85",
            "placeholder": "​",
            "style": "IPY_MODEL_4dcc160c8d72472193f5ac04f4ed90fb",
            "value": "Downloading: 100%"
          }
        },
        "40b2539e54d945929de4cd10acfd7b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63262f4ae6b24d0e82957671507c3a98",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f81fcc5c79c411caaed23cafe553dc3",
            "value": 52
          }
        },
        "e55de2a6365e462bbeb3636fd008ac08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a761004d4f04420891a6215e910044c6",
            "placeholder": "​",
            "style": "IPY_MODEL_8367e6400c424de08343f0f55d81bbcf",
            "value": " 52.0/52.0 [00:00&lt;00:00, 1.77kB/s]"
          }
        },
        "ac4544ac21e54e15ad79abad453c5591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbba42282654e94a9993d4e820c1d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dcc160c8d72472193f5ac04f4ed90fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63262f4ae6b24d0e82957671507c3a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f81fcc5c79c411caaed23cafe553dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a761004d4f04420891a6215e910044c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8367e6400c424de08343f0f55d81bbcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a0eae5bcad4ff588d2602ef1acf112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8583d8e44dc4459b498ea23fe0e5148",
              "IPY_MODEL_11fb46f6fddb406d87fc9253593cbe6c",
              "IPY_MODEL_d85553d12b7c423f8859a673d4b6c3b3"
            ],
            "layout": "IPY_MODEL_3ecc80c416bb421dad295dde04ffded8"
          }
        },
        "a8583d8e44dc4459b498ea23fe0e5148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c27e25bd6c4e3e843b7428af05f459",
            "placeholder": "​",
            "style": "IPY_MODEL_d6f96320355b4749984a3db17da0d55b",
            "value": "Downloading: 100%"
          }
        },
        "11fb46f6fddb406d87fc9253593cbe6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e302d6953a142039b26f4faca139ce3",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd08b940b3334e648cd2f9d4fc969969",
            "value": 2464616
          }
        },
        "d85553d12b7c423f8859a673d4b6c3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7bd807abe4c45638c9af1246f3a1e7f",
            "placeholder": "​",
            "style": "IPY_MODEL_b360670848374862833615e3588a3b51",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 12.2MB/s]"
          }
        },
        "3ecc80c416bb421dad295dde04ffded8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c27e25bd6c4e3e843b7428af05f459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f96320355b4749984a3db17da0d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e302d6953a142039b26f4faca139ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd08b940b3334e648cd2f9d4fc969969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7bd807abe4c45638c9af1246f3a1e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b360670848374862833615e3588a3b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8038544f5a499694ae15d575fe668a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8803e9685674aa4956a480b1a3b8d37",
              "IPY_MODEL_78fd9011fbaa46518d5a1096b0599085",
              "IPY_MODEL_62f97a5098934a88a1eeb1d4617e813a"
            ],
            "layout": "IPY_MODEL_afce691c3d024257b01bf9ccef947ce2"
          }
        },
        "b8803e9685674aa4956a480b1a3b8d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e019fbd4953c4d7d94a657881c081f16",
            "placeholder": "​",
            "style": "IPY_MODEL_8c3bc45fd755406d8810222f07cf4168",
            "value": "Downloading: 100%"
          }
        },
        "78fd9011fbaa46518d5a1096b0599085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba4d1f13c95497b846b6dd4bc8aa80b",
            "max": 580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13b85a4efc0c497eb923545008a009b0",
            "value": 580
          }
        },
        "62f97a5098934a88a1eeb1d4617e813a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738e6e0fd1c84a1bb68819570bc55673",
            "placeholder": "​",
            "style": "IPY_MODEL_1ce8a0c03fec4a6984b0cba35d9d8995",
            "value": " 580/580 [00:00&lt;00:00, 20.2kB/s]"
          }
        },
        "afce691c3d024257b01bf9ccef947ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e019fbd4953c4d7d94a657881c081f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3bc45fd755406d8810222f07cf4168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ba4d1f13c95497b846b6dd4bc8aa80b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b85a4efc0c497eb923545008a009b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "738e6e0fd1c84a1bb68819570bc55673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ce8a0c03fec4a6984b0cba35d9d8995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "512951085bfd43c5a9d44edcb89c7be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8c0c34af71a4f48a3c55f851d3b14cb",
              "IPY_MODEL_d3266a0373d04901a70f1f8cd5fafbe5",
              "IPY_MODEL_04199e3f15ac42359c2a487241d0282e"
            ],
            "layout": "IPY_MODEL_525ce9a871ec4f37bac094e765c013e9"
          }
        },
        "b8c0c34af71a4f48a3c55f851d3b14cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4923498582e54692ab027843c76cfc78",
            "placeholder": "​",
            "style": "IPY_MODEL_d9e75978f3964644b48a5197db26d049",
            "value": "Downloading: 100%"
          }
        },
        "d3266a0373d04901a70f1f8cd5fafbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_428f3b3893dd47e5bffdde9bb37f8f73",
            "max": 873673253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c86d955ea81b470cb741522a27a39e3b",
            "value": 873673253
          }
        },
        "04199e3f15ac42359c2a487241d0282e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7ff016a988422f8bc6323856786fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_9d3e16843ef64921b40002a657a54779",
            "value": " 874M/874M [00:14&lt;00:00, 63.9MB/s]"
          }
        },
        "525ce9a871ec4f37bac094e765c013e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4923498582e54692ab027843c76cfc78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e75978f3964644b48a5197db26d049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "428f3b3893dd47e5bffdde9bb37f8f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86d955ea81b470cb741522a27a39e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a7ff016a988422f8bc6323856786fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3e16843ef64921b40002a657a54779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!mkdir -p ./data/raw\n",
        "!mkdir -p ./data/processed\n",
        "!gdown 1pv7dFLniLEMJXXk5-YL3_kWxpOs7ueJt -O ./data.zip\n",
        "!unzip ./data.zip -d ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTcW735Fh46U",
        "outputId": "48472515-68a0-40f0-d920-03e8572adced"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pv7dFLniLEMJXXk5-YL3_kWxpOs7ueJt\n",
            "To: /content/data.zip\n",
            "100% 9.35M/9.35M [00:00<00:00, 214MB/s]\n",
            "Archive:  ./data.zip\n",
            "  inflating: ./data/processed/wiki_masks.json  \n",
            "  inflating: ./data/processed/jg_dev_masks.json  \n",
            "  inflating: ./data/processed/echr_train_masks.json  \n",
            "  inflating: ./data/processed/echr_dev_masks.json  \n",
            "  inflating: ./data/processed/echr_test_masks.json  \n",
            "  inflating: ./data/processed/jg_test_masks.json  \n",
            "  inflating: ./data/processed/jg_train_masks.json  \n",
            "   creating: ./data/raw/text-anonymization-benchmark/\n",
            "  inflating: ./data/raw/text-anonymization-benchmark/README.md  \n",
            "  inflating: ./data/raw/text-anonymization-benchmark/LICENSE.txt  \n",
            "  inflating: ./data/raw/text-anonymization-benchmark/echr_dev.json  \n",
            "  inflating: ./data/raw/text-anonymization-benchmark/echr_test.json  \n",
            "  inflating: ./data/raw/text-anonymization-benchmark/echr_train.json  \n",
            "  inflating: ./data/raw/text-anonymization-benchmark/evaluation.py  \n",
            "  inflating: ./data/raw/text-anonymization-benchmark/guidelines.md  \n",
            "   creating: ./data/raw/wiki-summaries/\n",
            "  inflating: ./data/raw/wiki-summaries/.Rhistory  \n",
            "  inflating: ./data/raw/wiki-summaries/README.md  \n",
            "  inflating: ./data/raw/wiki-summaries/annotated_wikipedia.json  \n",
            "  inflating: ./data/raw/wiki-summaries/annotation_guidelines.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cboHJMR6imu5",
        "outputId": "5e73b778-ee6e-4655-a658-9b1c42ba98cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 21 06:50:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    45W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "!pip install transformers[sentencepiece]\n",
        "!pip install torch\n",
        "!pip install json\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpfh4gxGi4J3",
        "outputId": "6f8fda04-0a76-47de-de4c-fd546ad95a00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 6.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.13.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 84.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.13.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers[sentencepiece]) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.9.24)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for json\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=cc4075db0dfd08c8b055c09eb7b3798615c73ef86a8ce0da5ee110d05d5054a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8TV2efoQf_11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713,
          "referenced_widgets": [
            "aed0441557fa4ad683ecfdf43c0c9ae5",
            "791a96d746bf494aa70bef1c823004bf",
            "40b2539e54d945929de4cd10acfd7b7d",
            "e55de2a6365e462bbeb3636fd008ac08",
            "ac4544ac21e54e15ad79abad453c5591",
            "ffbba42282654e94a9993d4e820c1d85",
            "4dcc160c8d72472193f5ac04f4ed90fb",
            "63262f4ae6b24d0e82957671507c3a98",
            "4f81fcc5c79c411caaed23cafe553dc3",
            "a761004d4f04420891a6215e910044c6",
            "8367e6400c424de08343f0f55d81bbcf",
            "52a0eae5bcad4ff588d2602ef1acf112",
            "a8583d8e44dc4459b498ea23fe0e5148",
            "11fb46f6fddb406d87fc9253593cbe6c",
            "d85553d12b7c423f8859a673d4b6c3b3",
            "3ecc80c416bb421dad295dde04ffded8",
            "b1c27e25bd6c4e3e843b7428af05f459",
            "d6f96320355b4749984a3db17da0d55b",
            "0e302d6953a142039b26f4faca139ce3",
            "fd08b940b3334e648cd2f9d4fc969969",
            "f7bd807abe4c45638c9af1246f3a1e7f",
            "b360670848374862833615e3588a3b51",
            "ab8038544f5a499694ae15d575fe668a",
            "b8803e9685674aa4956a480b1a3b8d37",
            "78fd9011fbaa46518d5a1096b0599085",
            "62f97a5098934a88a1eeb1d4617e813a",
            "afce691c3d024257b01bf9ccef947ce2",
            "e019fbd4953c4d7d94a657881c081f16",
            "8c3bc45fd755406d8810222f07cf4168",
            "0ba4d1f13c95497b846b6dd4bc8aa80b",
            "13b85a4efc0c497eb923545008a009b0",
            "738e6e0fd1c84a1bb68819570bc55673",
            "1ce8a0c03fec4a6984b0cba35d9d8995",
            "512951085bfd43c5a9d44edcb89c7be0",
            "b8c0c34af71a4f48a3c55f851d3b14cb",
            "d3266a0373d04901a70f1f8cd5fafbe5",
            "04199e3f15ac42359c2a487241d0282e",
            "525ce9a871ec4f37bac094e765c013e9",
            "4923498582e54692ab027843c76cfc78",
            "d9e75978f3964644b48a5197db26d049",
            "428f3b3893dd47e5bffdde9bb37f8f73",
            "c86d955ea81b470cb741522a27a39e3b",
            "1a7ff016a988422f8bc6323856786fa2",
            "9d3e16843ef64921b40002a657a54779"
          ]
        },
        "outputId": "3d2a0964-d1a0-4bc8-90ea-1b14df89ae92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aed0441557fa4ad683ecfdf43c0c9ae5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52a0eae5bcad4ff588d2602ef1acf112"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab8038544f5a499694ae15d575fe668a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/874M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "512951085bfd43c5a9d44edcb89c7be0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "100%|██████████| 152/152 [02:46<00:00,  1.10s/it]\n",
            "100%|██████████| 32/32 [00:08<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.6605746185309008 Valid Loss = 0.6514885742217302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 152/152 [02:46<00:00,  1.10s/it]\n",
            "100%|██████████| 32/32 [00:08<00:00,  3.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.6371891839723838 Valid Loss = 0.6327233463525772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 152/152 [02:46<00:00,  1.10s/it]\n",
            "100%|██████████| 32/32 [00:08<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.6188475485695036 Valid Loss = 0.6184502393007278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 152/152 [02:46<00:00,  1.10s/it]\n",
            "100%|██████████| 32/32 [00:08<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.6055392732745722 Valid Loss = 0.6086983643472195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 152/152 [02:46<00:00,  1.10s/it]\n",
            "100%|██████████| 32/32 [00:08<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.5969837649088157 Valid Loss = 0.6030509918928146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 152/152 [02:46<00:00,  1.10s/it]\n",
            "100%|██████████| 32/32 [00:08<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss = 0.5928035903918115 Valid Loss = 0.6011965349316597\n"
          ]
        }
      ],
      "source": [
        "import tokenizers\n",
        "import transformers\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import DebertaV2TokenizerFast\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import sentencepiece\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "VERSION = 'v2.BCE'\n",
        "#max token input length\n",
        "MAX_LEN = 768\n",
        "TRAIN_BATCH_SIZE = 6#32\n",
        "VALID_BATCH_SIZE = 4#8\n",
        "EPOCHS =6 #10\n",
        "BASE_MODEL = 'microsoft/deberta-v3-large'\n",
        "#BASE_MODEL = 'microsoft/deberta-v3-small'\n",
        "\n",
        "MODEL_PATH = \"model_\" + BASE_MODEL.replace('/','_') + \"_\" + VERSION + \".bin\"\n",
        "#TOKENIZER = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "TOKENIZER = DebertaV2TokenizerFast.from_pretrained(BASE_MODEL)\n",
        "\n",
        "DEV_FILE = \"./data/raw/text-anonymization-benchmark/echr_dev.json\"\n",
        "TRAINING_FILE = \"./data/raw/text-anonymization-benchmark/echr_train.json\"\n",
        "TEST_FILE = \"./data/raw/text-anonymization-benchmark/echr_test.json\"\n",
        "\n",
        "DEV_MASKS_FILE =    \"./data/processed/jg_dev_masks.json\"\n",
        "TRAIN_MASKS_FILE =  \"./data/processed/jg_train_masks.json\"\n",
        "TEST_MASKS_FILE =   \"./data/processed/jg_test_masks.json\"\n",
        "\n",
        "class EntityDataset:\n",
        "    def __init__(self, texts, ids, labels, offsets, masks):\n",
        "        # ids: [[    0,  4454,  4571,  1691, 12435, 50118, ..., 4, 2], [0, 50118,   133,   403, 19575,    11,    41, ..., 2]]\n",
        "        # texts - original texts\n",
        "        # offsets - mapping of tokens to text \n",
        "        # labels: is token an identifier: [[0,0,0,0,1,1,0,0, ...,], [0,0,1,0,0,...]]\n",
        "        self.texts = texts\n",
        "        self.ids = ids\n",
        "        self.offsets = offsets\n",
        "        self.labels = labels\n",
        "        self.masks = masks\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        ids = self.ids[item]\n",
        "        masks = self.masks[item]\n",
        "        \n",
        "        target_labels =self.labels[item]\n",
        "        #pad if we need to\n",
        "        if len(target_labels) < MAX_LEN:\n",
        "            target_labels = np.pad(target_labels, (0,MAX_LEN-target_labels.size),'constant', constant_values=(0))\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"masks\": torch.tensor(masks, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(target_labels, dtype=torch.float32),\n",
        "        }\n",
        "    #for debugging\n",
        "    def printItem(i):\n",
        "        masked_doc_text=''\n",
        "        for token, offset, label in zip(tokens, offsets, labels):\n",
        "            if label == 1:\n",
        "                #masked_doc_text.append(\"[MASK]\")\n",
        "                str=\"*\" + texts[offset[0]:offset[1]] +\"*\"        \n",
        "                masked_doc_text.append(str)\n",
        "            else:\n",
        "                masked_doc_text.append(texts[offset[0]:offset[1]])\n",
        "        print(masked_doc_text)\n",
        "\n",
        "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    final_loss = 0\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        _, loss = model(**data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        final_loss += loss.item()\n",
        "    return final_loss / len(data_loader)\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    final_loss = 0\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        _, loss = model(**data)\n",
        "        final_loss += loss.item()\n",
        "    return final_loss / len(data_loader)\n",
        "\n",
        "def loss_fn(out_logits, target, mask):\n",
        "    lfn = nn.BCELoss()    \n",
        "    #for BCE\n",
        "    m = nn.Sigmoid()    \n",
        "    loss = lfn(m(out_logits), target)\n",
        "    return loss\n",
        "\n",
        "class MeanPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MeanPooling, self).__init__()\n",
        "        \n",
        "    def forward(self, last_hidden_state, labels, attention_mask):\n",
        "        #last_hidden_state.shape = [|b|,768,1024].  For deberta-small: [|b|,768,768]\n",
        "        #attention_mask = [[1,1,1,1... 1,0,0,0]].  attention_mask.shape = [1,768].  For deberta-small = [768, 32]\n",
        "        #desired output shape: [|b|, 768]\n",
        "        #unsqueeze to add 1 dim, then duplicate in dimension to match the second hidden state dim (768)\n",
        "        #tt_mask = attention_mask.unsqueeze(-1)\n",
        "        #input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.shape[1]).float()  \n",
        "        #sum the hidden state tensor along the 2 dimension (1024)\n",
        "        \n",
        "        #for small:\n",
        "        sum_embeddings = torch.sum(last_hidden_state, 2)        \n",
        "        sum_embeddings = torch.mul(sum_embeddings, attention_mask)        \n",
        "        mean_embeddings = sum_embeddings / last_hidden_state.shape[2]\n",
        "        return mean_embeddings\n",
        "\n",
        "class EntityModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EntityModel, self).__init__()\n",
        "        #full config\n",
        "        #https://huggingface.co/docs/transformers/model_doc/deberta-v2\n",
        "        self.config = AutoConfig.from_pretrained(BASE_MODEL, return_dict=True)\n",
        "        self.m = AutoModel.from_pretrained(BASE_MODEL, config=self.config) \n",
        "        self.mpool = MeanPooling()\n",
        "    \n",
        "    def forward(self, ids, masks, labels):\n",
        "        output = self.m(ids, attention_mask=masks)\n",
        "        mpool = self.mpool(output.last_hidden_state, labels, masks)\n",
        "        loss_labels = loss_fn(mpool, labels, masks)        \n",
        "        return labels, loss_labels\n",
        "\n",
        "# Function used to label data\n",
        "def label_tokens(toks, offs, spans_to_mask):\n",
        "    \"\"\"Args: \n",
        "            toks - list of token id's\n",
        "            offs - list of char offsets for each token\n",
        "       Returns:\n",
        "            label_list - 0 for non_mask, 1 for mask\"\"\"\n",
        "    \n",
        "    label_list = []\n",
        "    mapping_list = []    \n",
        "    # Map token_ids back to string    \n",
        "    for token, pos in zip(toks, offs):\n",
        "        mapping_list.append([token, pos[0], pos[1]])\n",
        "    \n",
        "    # Determine if each token should be masked\n",
        "    spans_to_mask.sort(key=lambda tup: tup[0]) #order spans, ascending\n",
        "    \n",
        "    j=0\n",
        "    for i in range(len(mapping_list)):\n",
        "        temp_list = []\n",
        "        stop=False        \n",
        "        while not stop and j < len(spans_to_mask):            \n",
        "            if (mapping_list[i][1] >= spans_to_mask[j][0]) and (mapping_list[i][2] <= spans_to_mask[j][1]):\n",
        "                temp_list.append(1)\n",
        "            else:\n",
        "                temp_list.append(0)           \n",
        "\n",
        "            # Since spans and mapping_list are ordered, break to allow it to catch up\n",
        "            if(spans_to_mask[j][1] > mapping_list[i][2]):\n",
        "                stop=True\n",
        "            else:\n",
        "                j = j+1\n",
        "            \n",
        "        if sum(temp_list) >= 1:\n",
        "            label_list.append(1)\n",
        "        else:\n",
        "            label_list.append(0)\n",
        "    return label_list  \n",
        "\n",
        "def process_data(data_path, masks_path):\n",
        "    with open(data_path) as file:\n",
        "        file = json.load(file)\n",
        "\n",
        "    with open(masks_path) as masks_file:\n",
        "        train_masks = json.load(masks_file)\n",
        "\n",
        "    text = []\n",
        "    tokens = []\n",
        "    offsets = []\n",
        "    labels = []\n",
        "    masks = []\n",
        "\n",
        "    for i in range(len(file)):\n",
        "        doc_id = file[i][\"doc_id\"]\n",
        "        spans_to_mask = train_masks[doc_id]\n",
        "        spans_to_mask = list({tuple(x) for x in spans_to_mask}) # Make spans unique\n",
        "        doc_text = file[i][\"text\"]\n",
        "        tok_tensor = TOKENIZER.encode_plus(\n",
        "            doc_text,\n",
        "            add_special_tokens=True,            \n",
        "            max_length=MAX_LEN,\n",
        "            truncation=True,                #Truncate at MAX_LEN for now.  Can try setting MAX_LEN to the longest text.\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',            #pytorch tensors\n",
        "            return_offsets_mapping = True\n",
        "        )\n",
        "        \n",
        "        #TOKENIZER(doc_text, return_tensors=\"tf\", truncation=True, padding=True, return_offsets_mapping=True)\n",
        "        doc_tokens = tok_tensor[\"input_ids\"].numpy()[0]\n",
        "        doc_offsets = tok_tensor[\"offset_mapping\"].numpy()[0]\n",
        "        masks_ = tok_tensor[\"attention_mask\"].numpy()[0]\n",
        "       \n",
        "        labels.append(label_tokens(doc_tokens, doc_offsets, spans_to_mask))\n",
        "        masks.append(masks_)\n",
        "        tokens.append(doc_tokens)\n",
        "        offsets.append(doc_offsets)\n",
        "        text.append(doc_text)\n",
        "  \n",
        "    return text, tokens, labels, offsets, masks\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    testPredictRun=True\n",
        "\n",
        "    if testPredictRun:\n",
        "        single_doc = \"\"\"\n",
        "        The case originated in an application (no. 40593/04) against the Republic of Turkey lodged with the Court under Article 34 of the Convention for the Protection of Human Rights and Fundamental Freedoms (“the Convention”) by a Turkish national, Mr Cengiz Polat (“the applicant”), on 15 October 2004.\n",
        "        \"\"\"\n",
        "        tok_tensor = TOKENIZER.encode_plus(\n",
        "            single_doc,\n",
        "            add_special_tokens=True,            \n",
        "            max_length=MAX_LEN,\n",
        "            truncation=True,                #Truncate at MAX_LEN for now.  Can try setting MAX_LEN to the longest text.\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping = True\n",
        "        )\n",
        "        ids = tok_tensor[\"input_ids\"].numpy()[0]\n",
        "        #ids = tok_tensor.input_ids.flatten()\n",
        "        #mask = tok_tensor.attention_mask\n",
        "\n",
        "        test_dataset = EntityDataset(\n",
        "            texts=[single_doc], \n",
        "            ids=[ids],        \n",
        "            labels = [np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
        "            offsets = [tok_tensor[\"offset_mapping\"].numpy()[0]],\n",
        "            masks = [tok_tensor[\"attention_mask\"].numpy()[0]]\n",
        "        )\n",
        "\n",
        "        device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = EntityModel()\n",
        "        #model.load_state_dict(torch.load(MODEL_PATH))\n",
        "        #model.load_state_dict(torch.load(model))\n",
        "        model.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            data = test_dataset[0]\n",
        "            for k,v in data.items():\n",
        "                data[k] = v.to(device).unsqueeze(0)\n",
        "            #ids_test = data.get('ids')\n",
        "            #ids_size = ids_test.size()\n",
        "            \n",
        "            _, loss = model(**data)\n",
        "            #TODO: work out the loss function and evaluation here\n",
        "            #labels, loss_labels = model(**data)\n",
        "\n",
        "    texts, tokens, labels, offsets, masks = process_data(TRAINING_FILE, TRAIN_MASKS_FILE)\n",
        "\n",
        "    #Split train into train and test.  0.9/0.1 split\n",
        "    (\n",
        "        train_texts,\n",
        "        test_texts,\n",
        "        train_tokens,\n",
        "        test_tokens,\n",
        "        train_labels,\n",
        "        test_labels,\n",
        "        train_offsets,\n",
        "        test_offsets,\n",
        "        train_masks,\n",
        "        test_masks\n",
        "    ) = model_selection.train_test_split(texts, tokens, labels, offsets, masks, random_state=42, test_size=0.1)\n",
        "\n",
        "    train_dataset = EntityDataset(\n",
        "        texts=train_texts, ids=train_tokens, labels=train_labels, offsets=train_offsets, masks=train_masks\n",
        "    )\n",
        "    test_dataset = EntityDataset(\n",
        "        texts=test_texts, ids=test_tokens, labels=test_labels, offsets=test_offsets, masks=test_masks\n",
        "    )\n",
        "\n",
        "    texts, tokens, labels, offsets, masks = process_data(DEV_FILE, DEV_MASKS_FILE)\n",
        "    dev_dataset = EntityDataset(\n",
        "        texts=texts, ids=tokens, labels=labels, offsets=offsets, masks=masks\n",
        "    )\n",
        "    dev_data_loader = torch.utils.data.DataLoader(\n",
        "        dev_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=4\n",
        "    )\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=TRAIN_BATCH_SIZE, num_workers=4\n",
        "    )\n",
        "\n",
        "    texts, tokens, labels, offsets, masks = process_data(TEST_FILE, TEST_MASKS_FILE)\n",
        "    valid_dataset = EntityDataset(\n",
        "        texts=texts, ids=tokens, labels=labels, offsets=offsets, masks=masks\n",
        "    )\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=VALID_BATCH_SIZE, num_workers=1\n",
        "    )\n",
        "\n",
        "    device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = EntityModel()\n",
        "    model.to(device)\n",
        "\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_parameters = [\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "            ],\n",
        "            \"weight_decay\": 0.001,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "            ],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    num_train_steps = int(len(train_texts) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "    #num_train_steps = int(len(dev_dataset.texts)) / TRAIN_BATCH_SIZE * EPOCHS\n",
        "    optimizer = AdamW(optimizer_parameters, lr=3e-4)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_loss = np.inf\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
        "        test_loss = eval_fn(valid_data_loader, model, device)\n",
        "        print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\n",
        "        if test_loss < best_loss:\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            best_loss = test_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "8BwWrNzjRuYQ",
        "outputId": "8a855662-ac0e-4d4a-b09a-e7a32a662ec4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    6628 MB |   33676 MB |  160893 GB |  160886 GB |\\n|       from large pool |    6623 MB |   33669 MB |  160877 GB |  160871 GB |\\n|       from small pool |       4 MB |      18 MB |      15 GB |      15 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    6628 MB |   33676 MB |  160893 GB |  160886 GB |\\n|       from large pool |    6623 MB |   33669 MB |  160877 GB |  160871 GB |\\n|       from small pool |       4 MB |      18 MB |      15 GB |      15 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   11128 MB |   34680 MB |   34680 MB |   23552 MB |\\n|       from large pool |   11118 MB |   34660 MB |   34660 MB |   23542 MB |\\n|       from small pool |      10 MB |      20 MB |      20 MB |      10 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    4499 MB |   14939 MB |   64635 GB |   64631 GB |\\n|       from large pool |    4494 MB |   14934 MB |   64615 GB |   64611 GB |\\n|       from small pool |       5 MB |       8 MB |      20 GB |      20 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1565    |    2601    |    3974 K  |    3972 K  |\\n|       from large pool |     584    |    1407    |    3148 K  |    3147 K  |\\n|       from small pool |     981    |    1196    |     825 K  |     824 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1565    |    2601    |    3974 K  |    3972 K  |\\n|       from large pool |     584    |    1407    |    3148 K  |    3147 K  |\\n|       from small pool |     981    |    1196    |     825 K  |     824 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     119    |     233    |     233    |     114    |\\n|       from large pool |     114    |     223    |     223    |     109    |\\n|       from small pool |       5    |      10    |      10    |       5    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      88    |     265    |    2072 K  |    2072 K  |\\n|       from large pool |      74    |     243    |    1692 K  |    1692 K  |\\n|       from small pool |      14    |      23    |     380 K  |     380 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_DATA_NAME = \"WIKI_SUMMARIES\""
      ],
      "metadata": {
        "id": "Ph4Yf8Bi0830"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN_W = 768 # 730 is Longest sequence in wiki dataset\n",
        "# Load wiki data\n",
        "\n",
        "with open(\"./data/raw/wiki-summaries/annotated_wikipedia.json\") as file:\n",
        "    wiki_file = json.load(file)\n",
        "\n",
        "with open(\"./data/processed/wiki_masks.json\") as file:\n",
        "    wiki_masks = json.load(file)"
      ],
      "metadata": {
        "id": "9kJ6zPwH9pJW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels\n",
        "\n",
        "wiki_text = []\n",
        "wiki_labels = []\n",
        "\n",
        "for i in range(len(wiki_file)):\n",
        "    doc_id = wiki_file[i][\"doc_id\"]\n",
        "    spans_to_mask = wiki_masks[doc_id]\n",
        "    spans_to_mask = list({tuple(x) for x in spans_to_mask}) # Make spans unique\n",
        "    doc_text = wiki_file[i][\"text\"]\n",
        "    #tok_tensor = tokenizer(doc_text, return_tensors=\"tf\", truncation=True, padding=True, return_offsets_mapping=True)\n",
        "    tok_tensor = TOKENIZER.encode_plus(\n",
        "            doc_text,\n",
        "            add_special_tokens=True,            \n",
        "            max_length=MAX_LEN_W,\n",
        "            truncation=True,                #Truncate at MAX_LEN for now.  Can try setting MAX_LEN to the longest text.\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping = True\n",
        "        )\n",
        "    tokens = tok_tensor[\"input_ids\"].numpy()[0]\n",
        "    #tokens = tok_tensor[\"input_ids\"].numpy()[0]\n",
        "    offsets = tok_tensor[\"offset_mapping\"].numpy()[0]\n",
        "    wiki_text.append(doc_text)\n",
        "    wiki_labels.append(label_tokens(tokens, offsets, spans_to_mask))"
      ],
      "metadata": {
        "id": "sjc-YMOI-Vqz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad labels to max length\n",
        "def pad(arr):\n",
        "  for i in range(len(arr)):\n",
        "      curr_len = len(arr[i])\n",
        "      \n",
        "      if curr_len < MAX_LEN_W:\n",
        "          to_add = [0] * (MAX_LEN_W - curr_len)\n",
        "          arr[i].extend(to_add)\n",
        "          \n",
        "  arr = np.asarray(arr)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "iG4BHHa9_IPA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input\n",
        "wiki_text_tokenized = TOKENIZER(wiki_text, truncation=True, max_length=768, padding=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "uRGEeIoq_QEf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = EntityModel()\n",
        "loaded_model = loaded_model.to(device)\n",
        "loaded_model.load_state_dict(torch.load(MODEL_PATH))\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNMtP5y3OC-P",
        "outputId": "ef4eaaa1-c143-4058-ad0b-7664f159f9ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EntityModel(\n",
              "  (m): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (12): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (13): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (14): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (15): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (16): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (17): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (18): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (19): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (20): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (21): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (22): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (23): DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (mpool): MeanPooling()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_labels = pad(wiki_labels)\n",
        "ids_a= wiki_text_tokenized[\"input_ids\"]\n",
        "ids_a = F.pad(ids_a, (0,MAX_LEN - ids_a.shape[-1]))\n",
        "labels_a = torch.tensor(wiki_labels, dtype=torch.float32)\n",
        "zero_masks = torch.zeros_like(ids_a)"
      ],
      "metadata": {
        "id": "31dJumqsIgXo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "zero_masks = zero_masks.to(device)\n",
        "ids_a = ids_a.to(device)\n",
        "labels_a = labels_a.to(device)\n",
        "#wiki_text_tokenized[\"input_ids\"].to(device)\n",
        "#wiki_labels.to(device)\n",
        "predictions=[] #np.zeros(ids_a.shape)\n",
        "\n",
        "#m = nn.Sigmoid()\n",
        "with torch.no_grad():\n",
        "  batch_size=20\n",
        "  for i in range(0, ids_a.shape[0], batch_size):\n",
        "      num_in_batch = min(i+batch_size, ids_a.shape[0])\n",
        "      indices = range(i, num_in_batch)\n",
        "      ids_batch = ids_a[indices]\n",
        "      pred_logits, _ = loaded_model(ids= ids_batch, labels=labels_a[indices], masks=zero_masks[indices])\n",
        "      pred_logits = pred_logits.to(\"cpu\", dtype=torch.float)\n",
        "      #p_batch = (m(pred_logits))\n",
        "      #res = p_batch.tolist()\n",
        "      predictions.append(pred_logits.tolist()[0])\n",
        "      #loss = loss_fn(m(out_logits), labels_a[indices])\n",
        "      #print (loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZqkEhJJFcaw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt(\"./\" + MODEL_PATH + \"_\" + EVAL_DATA_NAME + \"_preds.txt\", predictions)"
      ],
      "metadata": {
        "id": "AhFa2EPXme0y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_precision(pred_list, label_list):\n",
        "    \"\"\"Calculates precision of batch of predictions\"\"\"\n",
        "    \n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    \n",
        "    for i in range(len(pred_list)):\n",
        "        for j in range(len(pred_list[i])):\n",
        "        \n",
        "            if pred_list[i][j] == 1:\n",
        "                if label_list[i][j] == 1:\n",
        "                    tp += 1\n",
        "                else:\n",
        "                    fp += 1\n",
        "            else:\n",
        "                continue\n",
        "                \n",
        "    return tp / (tp + fp)"
      ],
      "metadata": {
        "id": "Xkh0mzBOlzOl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_recall(pred_list, label_list):\n",
        "    \"\"\"Calculates recall of batch of predictions\"\"\"\n",
        "    \n",
        "    tp = 0 \n",
        "    fn = 0\n",
        "    \n",
        "    for i in range(len(pred_list)):\n",
        "        for j in range(len(pred_list[i])):\n",
        "            \n",
        "            if pred_list[i][j] == 1:\n",
        "                if label_list[i][j] == 1:\n",
        "                    tp += 1\n",
        "                else:\n",
        "                    tp += 0\n",
        "                \n",
        "            else:\n",
        "                if label_list[i][j] == 1:\n",
        "                    fn += 1\n",
        "                else:\n",
        "                    fn += 0\n",
        "    \n",
        "    return tp / (tp + fn)"
      ],
      "metadata": {
        "id": "UFaKfaJQl0Pc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = calc_precision(predictions, wiki_labels)\n",
        "print (f' Token level precision: {precision}')\n",
        "recall = calc_recall(predictions, wiki_labels)\n",
        "print (f' Token level recall: {recall}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1YTGAq_l2p8",
        "outputId": "32533882-aa80-4663-a126-556dd4919766"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Token level precision: 0.3328358208955224\n",
            " Token level recall: 0.24505494505494504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilabel indicators are not supported in sklearn for AUC\n",
        "# Loop through preds and take avg of AUC\n",
        "\n",
        "auc = []\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    \n",
        "    fpr, tpr, thresholds = metrics.roc_curve(wiki_labels[i], predictions[i], pos_label=1)\n",
        "    auc.append(metrics.auc(fpr, tpr))\n",
        "\n",
        "auc = sum(auc)/len(auc)\n",
        "print (f' Average AUC: {auc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxtYcLfFmIlr",
        "outputId": "9ac2203e-1695-4125-b71f-ac145fa24a51"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Average AUC: 0.6510879379084192\n"
          ]
        }
      ]
    }
  ]
}